Times:

10 simulations: 0m0.023s(record time using 0m0.000s format)
100 simulations: 0m0.023s (record time using 0m0.000s format)
1000 simulations: 0m0.041s (record time using 0m0.000s format)
10000 simulations: 0m0.087s (record time using 0m0.000s format)
100000 simulations: 0m0.687s (record time using 0m0.000s format)
1000000 simulations: 0m6.566s (record time using 0m0.000s format)

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?:

100 simulations, as there was not an increase in real time for the time taken to do the simulations

Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?:

I would say after 1,000,000 simulations as the law of large number becomes more prominent and into play and the time taken for the simulations substentialy increased, which can maybe imply